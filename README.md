# 介绍
这是一个使用基于[Ollama](https://ollama.com/)部署的本地语言模型来离线和实时翻译游戏文本的工具。工具运行需要安装Ollama以及部署本地模型，可翻译来自[MTool](https://mtool.app/)导出的离线文本，以及接收来自[XUnity.AutoTranslator](https://github.com/bbepis/XUnity.AutoTranslator)插件的在线文本。

其中，Unity实时翻译有明显延迟（本人的显卡为RTX3060 12GB），对于想要流畅的进行游戏的人来讲可能无法接受。如果你的设备具有强大的显卡，或者你愿意花费时间制作游戏的AI翻译版本，那这个工具也许是可行的选择。

另外，由于工具的开发初衷是自用，所以默认参数配置服务于日本R18同人游戏（即黄油）。你可以在工具第一次运行后生成的配置文件中更改这些参数。如果你不喜欢这些默认配置，你可以自行从代码中修改并构建。

这是本人第一次开发程序并发布在github上，如文档或程序有任何不当之处，还请指出。
# Ollama安装
这个工具的运行依赖于[Ollama](https://ollama.com/)及其部署的本地模型。
1. 在Ollama官网下载并安装Ollama。
2. 在Ollama官网搜索合适的模型。
这里推荐[qwen2.5](https://ollama.com/library/qwen2.5)，因为它的中文表现更好。注意，不要使用推理模型（reasoning model），如deepseek-r1和qwq，因为他们要生成大量思考过程，不适合翻译任务。
点击模型页面中的Tags可以看到模型的所有发布版本，根据你的设备选择合适的模型，根据我的经验，7b及以上的模型就可以生成不错的结果了。
3. 在本地部署模型
选择好模型后，在控制台（如cmd等）运行页面中提供的指令，如：
```
ollama run qwen2.5
```
这个命令会自动下载模型文件并运行。如果你只想拉取模型文件，那么使用pull指令，如：
```
ollama pull qwen2.5
```
# 基本使用
这个工具实际上包含了两个不同的工具，一个是离线翻译来自MTool工具导出的待翻译文件，另一个是通过本地代理为XUnity.Autotranslator插件提供实时翻译。

打开工具后选择离线模式和在线模式，离线模式就是MTool离线翻译，在线模式就是Unity实时翻译（不需要联网）。然后选择模型后，翻译就会开始。
## 离线翻译
你可以将MTool导出的待翻译文件（一般为`ManualTransFile.json`）拖动到工具上打开，也可以双击打开工具并选择离线模式后自行输入文件路径。Win 11用户可以直接右键->复制文件路径，或使用Ctrl+Shift+C快捷键来方便获取文件路径。

待翻译文件中一般有几万条文本，根据设备性能不同可能会需要几个小时。不过，翻译是分批处理并保存的，这意味着你可以随时关掉程序，下次打开时会自动加载缓存并从中途开始翻译。
翻译缓存保存在带翻译文件同目录下的`Temp Files`文件夹中，你可以删除其中任意的缓存文件，并运行工具对该部分重新翻译。

翻译成功后，会导出在同目录下`[文件名]_translated.json`中，你可以手动打开查看翻译结果，也可以用MTool打开游戏，并导入翻译文件查看效果。
## 实时翻译
首先，为确保翻译服务能正常运行，需要先将XUnity.AutoTranslator安装到游戏中，然后打开XUnity.AutoTranslator的配置文件，并找到并修改以下值：
```
[Service]
Endpoint=CustomTranslate

[General]
Language=zh-CN
FromLanguage=ja

[Custom]
Url=http://localhost:5000/translate
```
然后打开工具并选择在线模式，指定模型后，工具就会挂起一个本地代理，此时就可以patch并打开游戏并进行游玩了。

如介绍中所说，对于中低端设备来讲，延迟可能无法接受。如果你在制作游戏的离线翻译版本，那么在分享给别人前，可以将插件参数改回`Endpoint=GoogleTranslateV2`，以便他人碰到未翻译的文本能够实时翻译。
# 参数配置和翻译优化

## config.ini
配置文件格式如下，离线翻译和实时翻译有不同的配置文件。
```
[Model]
num_predict = 200                  ;输出结果的最大tokens数，约等于汉字数
temperature = 0.2                  ;控制结果的多样性，0-1，值越小越稳定
stop_words = 翻译,」」,]],)),））  ;停止词，当遇到停止词时停止生成，用于阻止异常生成

[History]
history_max_length = 20            ;翻译的实时对话历史的最大句数
clear_history = False              ;超过最大长度时是否清空对话历史

[System]
system_message =                   ;离线翻译时发送给模型的提示词，实时翻译时会被忽略

[Extra]
group_length = 1000                ;离线翻译的批次大小
system_message_template =          ;实时翻译时发送给模型的提示词模板，确保其中的{from_lang}{to_lang}不变
```
如果你发现翻译结果整体不理想，可以尝试修改配置中的提示词，`system_message`或`system_message_template`，这可以改变翻译的整体风格，和特定的翻译行为。

其中，工具翻译时会维护一个对话历史，更长的对话历史有给翻译结果带来更好的连贯性，但太长的历史会拖慢模型或者导致低质量的生成，同时，一个偶然的错误可能会由于对话历史而被模型延续下去，所以离线翻译的默认行为是超过最大长度时清空上下文。

如果你发现出现了成片的错误生成（这可能是因为显存波动导致的），你可以删除某个缓存文件来让工具重新翻译这部分文本。如果你更改了批次大小，那么你必须删除全部缓存文件。
## messages.json
同时，还有一个对话头的配置文件，这个对话头的文件内容如下：
```
{
    "原文1": "译文1",
    "原文2": "译文2",
    ......
}
```
这将作为一个固定的对话历史传递给模型，让模型觉得“我这样翻译过”。这会一定程度上影响模型的生成，尤其对于某些词汇的翻译。如果你在翻译某些特定题材的游戏，手动添加一些词汇会大大改善翻译。

添加短句和完整长句同样可以影响模型的翻译风格，但其整体风格或者某种特征，反过来劣化模型的翻译也存在可能。比如当上下文都是完整长句时，当模型收到一个中断的句子，他可能会尝试将其还原成完整的句子。
总之，可以多多尝试。
